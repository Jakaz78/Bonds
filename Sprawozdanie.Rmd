---
title: "Sprawozdanie"
author: "Jakub Kaźmierczyk"
date: "`r Sys.Date()`"
output:
  pdf_document:
    toc: true
    toc_depth: 4 
    number_sections: true
    latex_engine: xelatex
    highlight: tango
fontsize: 11pt
mainfont: "Times New Roman"
geometry: margin=2.5cm
linestretch: 1.5
lang: "pl"
header-includes:
  - \renewcommand{\contentsname}{Spis treści}
  - \usepackage{fancyhdr}
  - \pagestyle{fancy}
  - \fancyhf{}
  - \cfoot{\thepage}
---

# Wprowadzenie

## Opis projektu

Projekt ma na celu budowę kompleksowego modelu ekonometrycznego służącego do analizy i prognozowania rentowności 10-letnich polskich obligacji skarbowych. Model zostanie zbudowany na podstawie szeregów czasowych, co umożliwia głębszą analizę dynamicznych zależności ekonomicznych.

## Zmienne

### Zmienna objaśniana

**CLOSE** - rentowność 10-letnich polskich obligacji skarbowych

### Zmienne objaśniające

**10YDEBOND** - rentowność 10-letnich niemieckich obligacji skarbowych\
**10YUSBOND** - rentowność 10-letnich amerykańskich obligacji skarbowych\
**DETAL** - sprzedaź detaliczna miesiąc do miesiąca\
**XAUUSD** - cena złota w dolarze amerykańskim\
**S&P500** - ETF 500 największych notowanych na giełdzie amerykańskich spółek\
**PMI** - wskaźnik aktywności przemysłowej\
**WIG20** - 20 najwiekszych notowanych na gieldzie polskich spolek\
**OIL** - cena ropy naftowej za barylke\
**UNEMPLOYMENT** - stopa bezrobocia w Polsce\
**USDPLN** - kurs dolara amerykańskiego wyrażony w złotych\
**INFLATION** - inflacja rok do roku\
**WIBOR** - referencyjna stopa procentowa dla polskiego rynku międzybankowego\

## Źródła

[www.stooq.com](https://stooq.pl)\

\newpage

# Wczytywanie danych

Dane pochodzą ze strony www.stooq.com. Zawierają dane dotyczące zmiennych od czerwca 1999 do czerwca 2025, w interwale miesięcznym

```{r setup, echo=FALSE, warning=FALSE, message = FALSE}
library(corrplot)
library(readxl)
library(tinytex)
library(ggcorrplot)
library(urca)      
library(tseries)   
library(ggplot2)   
library(dplyr)     
library(tidyr)
library(zoo)
library(gridExtra)
library(grid)
library(lmtest)       
library(car)          
library(nortest)    
library(sandwich)     
library(strucchange)  
library(nlme)
```

```{r}
data_all <- read_excel("data.xlsx")
data_all <- data_all[, -c(1, 3, 4)]

data_all[] <- lapply(data_all, function(col) {
  na.approx(col, na.rm = FALSE)
})


n <- nrow(data_all)
train_size <- floor(0.8 * n)

data <- data_all[1:train_size, , drop = FALSE]
data_test  <- data_all[(train_size + 1):n, , drop = FALSE]

Y <- data["CLOSE"]
X <- data[, !names(data) %in% "CLOSE", drop = FALSE]
```

\newpage

# Podstawowe statystyki

## Zmienna objaśniana

```{r , echo=FALSE}
summary(Y)
```

Mediana rentowności 10-letnich polskich obligacji wynosi około 5,495 %, podczas gdy średnia to 5,610 %. Różnica mediana–średnia (5,495 vs 5,610) wskazuje niewielką prawą skośność rozkładu.

Minimalna zaobserwowana wartość to 1,843 %, a maksymalna aż 13,288 %. Zakres rozpiętości (13,288 – 1,843 = 11,445 punktu procentowego) jest stosunkowo szeroki, co sugeruje, że w okresie badanym zdarzały się uderzeniowe wahania rentowności.

Pierwszy kwartyl (3,457 %) i trzeci kwartyl (6,269 %) pokazują, że połowa obserwacji mieści się w zakresie od 3,457 % do 6,269 %. To oznacza, że większość wartości koncentruje się wokół poziomu 5 %–6 %.


## Zmienne objaśniające

```{r , echo=FALSE}
summary(X)
```

## Macierze korelacji

### Macierz korlelacji przed usunięciem zmiennych

```{r corrplot, fig.width=20, fig.height=20, echo=FALSE}
cor_matrix <- cor(data, use = "pairwise.complete.obs", method = "pearson")


    corrplot(cor_matrix, method = "color",
           order = "alphabet",
           addCoef.col = "black", 
           tl.col = "black", tl.cex = 2.5, cl.cex = 2.5, number.cex=2.6)
```

Z 11 zmiennych objaśniających wybrałem 7, których wartość bezwględna korelacji nie przekracza 0.8. INTERPRTACJA WYNIIKOW do zmiany

\newpage

### Macierz korlelacji po usunięciu zmiennych

```{r corrplot2, fig.width=20, fig.height=20, echo=FALSE}
data <- data[, !(colnames(data) %in% c("XAUUSD","WIBOR","10YDEBOND","10YUSBOND","DETAL","USDPLN"))]
data_test <- data_test[, !(colnames(data_test) %in% c("XAUUSD","WIBOR","10YDEBOND","10YUSBOND","DETAL","USDPLN"))]
data <- data[1:train_size, , drop = FALSE]



cor_matrix <- cor(data, use = "pairwise.complete.obs", method = "pearson")


    corrplot(cor_matrix, method = "color",
           order = "alphabet",
           addCoef.col = "black", 
           tl.col = "black", tl.cex = 2.5, cl.cex = 2.5, number.cex=2.6)
```

\newpage

# Identyfikacja niestacjonarnych zmiennych objaśniających

```{r analiza_stacjonarnosci, warning=FALSE, message=FALSE, echo=FALSE}

check_stationarity <- function(x) {
  adf_test <- ur.df(x, type = "trend")@teststat[1] < ur.df(x, type = "trend")@cval[1,"5pct"]
  kpss_test <- kpss.test(x)$p.value > 0.05
  return(adf_test & kpss_test)
}

non_stationary_vars <- c()

for (var in colnames(data)) {
  series <- ts(data[[var]])
  if (!check_stationarity(series)) {
    non_stationary_vars <- c(non_stationary_vars, var)
  }
}

```



## Sprawdzenie niestacjonarności zmiennych

```{r , echo=FALSE, comment=NA, warning=FALSE, message=FALSE}
stationarity_df <- data.frame(
  Zmienna = colnames(data),
  Stacjonarnosc = sapply(data, function(col) {
    if (check_stationarity(ts(col))) {
      return("Stacjonarna")
    } else {
      return("Niestacjonarna")
    }
  })
)


knitr::kable(stationarity_df, row.names = FALSE)

```

Wszystkie zmienne w pierwotnej postaci (zarówno CLOSE, jak i 6 zmiennych objaśniających: INFLATION, WIG20, S&P500, UNEMPLOYMENT, PMI, OIL) okazały się niestacjonarne (wyniki testów ADF wskazywały p-value > 0,05 lub wartość statystyki testowej wyższa od wartości krytycznej; KPSS p-value < 0,05).

Oznacza to, że w danych występuje wspólny trend lub efekt niestacjonarności, co skłania do zastosowania różnicowania, by usunąć jednostkowe pierwiastki i otrzymać procesy stacjonarne

## Usunięcie niestacjonarności

```{r usuwanie_niestacjonarnosci, message=FALSE, echo=FALSE, comment = NA }

dir.create("plots", showWarnings = FALSE)

remove_nonstationarity <- function(data, non_stationary_vars, max_diff = 2, 
                                   show_plots = TRUE, save_plots = FALSE, 
                                   plot_dir = "plots") {
  if (save_plots && !dir.exists(plot_dir)) {
    dir.create(plot_dir, recursive = TRUE)
  }

  transformed_data <- list()
  diff_info <- list()
  plots_before <- list()
  plots_after <- list()

  for (var_name in colnames(data)) {
    original_series <- data[[var_name]]
    current_series <- original_series
    order <- 0

    if (var_name %in% non_stationary_vars) {
      for (i in 1:max_diff) {
        test_series <- if (i == 0) original_series else diff(original_series, differences = i)

        if (check_stationarity(test_series)) {
         order <- i
         current_series <- test_series
         break
       }

        if (i == max_diff) {
          order <- max_diff
          current_series <- diff(original_series, differences = max_diff)
        }
      }
    }

   new_name <- if (order > 0) {
     paste0("D", if(order > 1) order else "", "_", var_name)} else {
     var_name
   }
   
   diff_info[[var_name]] <- list(order = order, name = new_name)
   transformed_data[[new_name]] <- current_series

    if (show_plots || save_plots) {
      df_plot_before <- data.frame(Index = 1:length(original_series), Value = as.numeric(original_series))
      df_plot_after  <- data.frame(Index = 1:length(current_series), Value = as.numeric(current_series))

      plot_before <- ggplot(df_plot_before, aes(x = Index, y = Value)) +
        geom_line(color = "blue", size = 0.7) +
        labs(title = paste("Przed:", var_name, "Liczba różnicowań: ",order), x = "Czas", y = "Wartość") +
        theme_minimal() +
        theme(plot.title = element_text(size = 10, face = "bold"))

      plot_after <- ggplot(df_plot_after, aes(x = Index, y = Value)) +
        geom_line(color = "red", size = 0.7) +
        labs(title = paste("Po:", new_name), x = "Czas", y = "Wartość") +
        theme_minimal() +
        theme(plot.title = element_text(size = 10, face = "bold"))

      plots_before[[var_name]] <- plot_before
      plots_after[[var_name]] <- plot_after

      if (save_plots) {
        ggsave(filename = file.path(plot_dir, paste0("before_", var_name, ".png")),
               plot = plot_before, width = 6, height = 4, dpi = 300)
        ggsave(filename = file.path(plot_dir, paste0("after_", new_name, ".png")),  
               plot = plot_after, width = 6, height = 4, dpi = 300)
      }
    }
    
  }

  max_diff_order <- max(sapply(diff_info, function(x) x$order))

  final_df <- as.data.frame(lapply(transformed_data, function(x) {
    c(rep(NA, max_diff_order), x)[1:(nrow(data) + max_diff_order)]
  }))
  final_df <- final_df[complete.cases(final_df), ]

  return(list(
    data = final_df,
    diff_info = diff_info,
    plots_before = plots_before,
    plots_after = plots_after
  ))
}

```

```{r wywołanie_funkcji, echo=FALSE, warning=FALSE, message=FALSE, comment=NA, fig.align='center', fig.width=10, fig.height=6}

non_stationary_vars <- c()

for (var in colnames(data)) {
  series <- ts(data[[var]])
  if (!check_stationarity(series)) {
    non_stationary_vars <- c(non_stationary_vars, var)
  }
}

result <- remove_nonstationarity(
  data,
  non_stationary_vars,
  save_plots = TRUE,
  show_plots = FALSE
)

data_stationary <- result$data
diff_info <- result$diff_info
plots_before <- result$plots_before
plots_after <- result$plots_after

for (var in names(diff_info)) {
  info <- diff_info[[var]]
  plot_before <- plots_before[[var]]
  plot_after <- plots_after[[var]]
  
  gridExtra::grid.arrange(
    plot_before, plot_after,
    ncol = 2,
    top = NULL
  )
}
```

## Ponowne sprawdzenie niestacjonarności zmiennych

```{r sprawdzenie_zmienncyh, echo=FALSE, warning=FALSE, message=FALSE, comment = NA}
stationarity_df <- data.frame(
  Zmienna = colnames(data_stationary),
  Stacjonarnosc = sapply(data_stationary, function(col) {
    if (check_stationarity(ts(col))) {
      return("Stacjonarna")
    } else {
      return("Niestacjonarna")
    }
  })
)


knitr::kable(stationarity_df, row.names = FALSE)
```


Wszystkie zmienne przekształcone do postaci różnicowej (D_CLOSE, D_INFLATION, D_WIG20, D2_S.P500, D_UNEMPLOYMENT, D_PMI, D_OIL) okazały się stacjonarne (test AD-Fuller zakończył się odrzuceniem hipotezy o istnieniu pierwiastka jednostkowego, a test KPSS nie wskazał na niestacjonarność).

Oznacza to, że proces różnicowania był wystarczający – w dalszej części modelu możemy bezpiecznie użyć tych stacjonarnych serii jako zmiennych w regresji liniowej.


## Sprawdzenie korelacji po usunięciu niestacjonarności

```{r, fig.width=20, fig.height=20, echo=FALSE}

cor_matrix <- cor(data_stationary, use = "pairwise.complete.obs", method = "pearson")


    corrplot(cor_matrix, method = "color",
           order = "alphabet",
           addCoef.col = "black", 
           tl.col = "black", tl.cex = 2.5, cl.cex = 2.5, number.cex=2.6)
```


## Usunięcie zmiennych o zerowej wariancji

### Przed usunięciem

```{r , echo=FALSE, warning=FALSE, message=FALSE, comment = NA}
for (col_name in colnames(data_stationary)) {
  
      col_cv <- sd(data_stationary[[col_name]]) / mean(data_stationary[[col_name]]) * 100
      col_var <- var(data_stationary[[col_name]])
      cat(col_name, "- Współczynnik zmienności:", col_cv, "%, Wariancja: ", col_var,"\n")
}



#usuwam zmienne o prawie 0 wariancji i helwwig spada

data_stationary <- data_stationary[, !(colnames(data_stationary) %in% c("D_UNEMPLOYMENT","D_INFLATION"))]


```

Z uwagi na bardzo niską wariancję D_UNEMPLOYMENT i D_INFLATION zdecydowałem się usunąć te zmienne, bo nie wnoszą istotnej zmienności do zestawu predyktorów.

### Po usunięciu

```{r , echo=FALSE, warning=FALSE, message=FALSE, comment = NA}

for (col_name in colnames(data_stationary)) {
  
      col_cv <- sd(data_stationary[[col_name]]) / mean(data_stationary[[col_name]]) * 100
      col_var <- var(data_stationary[[col_name]])
      cat(col_name, "- Współczynnik zmienności:", col_cv, "%, Wariancja: ", col_var,"\n")
}
```

\newpage

# Metoda doboru zmiennych

## Metoda Hellwiga

DLACZEGO HELLWIG?

```{r , echo=FALSE, warning=FALSE, message=FALSE, comment = NA}
hellwig_method_original <- function(y, X) {
  all_vars <- colnames(X)
  R <- cor(cbind(y, X))
  r0 <- R[-1, 1]        
  Rxx <- R[-1, -1]      
  results <- list()
  
  for (k in 1:length(all_vars)) {
    combos <- combn(all_vars, k, simplify = FALSE)
    
    for (combo in combos) {
      indices <- match(combo, all_vars)
      r0_sub <- r0[indices]
      Rxx_sub <- Rxx[indices, indices]
      
      h_kj <- numeric(length(indices))
      
      for (j in seq_along(indices)) {
        if (length(indices) == 1) {
          denom <- 1  
        } else {
          denom <- 1 + sum(abs(Rxx_sub[j, -j]))
        }
        h_kj[j] <- (r0_sub[j]^2) / denom
      }
      
      H_k <- sum(h_kj)
      results[[paste(combo, collapse = ", ")]] <- H_k
    }
  }
  
  df <- data.frame(
    Zmienne = names(results),
    Pojemnosc_Hellwiga = round(unlist(results), 4),
    row.names = NULL
  )
  
  df <- df[order(-df$Pojemnosc_Hellwiga), ]
  return(df)
}
X_stat <- data_stationary[, -1]         
Y_stat <- data_stationary["D_CLOSE"]    
hellwig_result <- hellwig_method_original(Y_stat, X_stat)
```

```{r, echo=FALSE, warning=FALSE, message=FALSE, comment = NA}
najlepsza_kombinacja_string <- hellwig_result$Zmienne[1]
best_hellwig_vars <- unlist(strsplit(najlepsza_kombinacja_string, ", "))
cat("Zmienne składowe w najlepszej kombinacji:\n")
for (zmienna in best_hellwig_vars) {
  writeLines(zmienna)
}
cat("Pojemność Hellwiga dla tej kombinacji:", hellwig_result$Pojemnosc_Hellwiga[1], "\n")

zmienne_objaśniające_do_modelu <- unlist(strsplit(najlepsza_kombinacja_string, ", "))



```

Pojemność Hellwiga dla tej kombinacji wynosi 0,0741. Oznacza to, że te dwie zmienne razem wyjaśniają około 7,41 % wariancji zmiennej D_CLOSE.
\newpage

# Tworzenie modelu ekonometrycznego

```{r message=FALSE, comment=NA}

formula_modelu <- reformulate(best_hellwig_vars, response = "D_CLOSE")

model <- lm(formula_modelu, data = data_stationary)

print(summary(model))
```

Statystyka F = 13,66 (df = 2 i 243), p-value ≈ 2,388×10⁻⁶. Oznacza to, że jako całość model jest istotny statystycznie – przynajmniej jedna ze zmiennych objaśniających przyczynia się do wyjaśnienia zmienności D_CLOSE

R-kwadrat: 0,1011 → model wyjaśnia tylko około 10,11 % zmienności zmiennej D_CLOSE. Po skorygowaniu R²_adj = 0,0937. Tę wartość można uznać za dosyć niską (model w obecnej formie jest słaby), co sugeruje, że istnieje wiele innych czynników wpływających na zmiany rentowności obligacji, których nie uwzględniono.

\newpage

# Niby TEST

## Testowanie normalności rozkładu reszt

```{r, echo=FALSE}

# Przygotowanie reszt
residuals_model <- residuals(model)
fitted_values <- fitted(model)
n_obs <- length(residuals_model)
n_params <- length(coef(model))
cat("TEORIA: Testy normalności sprawdzają czy reszty mają rozkład normalny.\n")
cat("H0: Reszty mają rozkład normalny\n")
cat("H1: Reszty nie mają rozkładu normalnego\n")
cat("Poziom istotności: α = 0.05\n\n")
```

### Test Shapiro-Wilka

```{r, echo=FALSE}

  shapiro_test <- shapiro.test(residuals_model)
  cat("   Statystyka W =", round(shapiro_test$statistic, 4), "\n")
  cat("   p-value =", round(shapiro_test$p.value, 4), "\n")
  cat("   Wniosek:", ifelse(shapiro_test$p.value > 0.05, 
                           "Nie ma podstaw do odrzucenia H0 - reszty są normalne",
                           "Odrzucamy H0 - reszty nie są normalne"), "\n\n")
```

### Test Jarque-Bera

```{r, echo=FALSE}
# Test Jarque-Bera
jb_test <- jarque.bera.test(residuals_model)
cat("   Statystyka JB =", round(jb_test$statistic, 4), "\n")
cat("   p-value =", round(jb_test$p.value, 4), "\n")
cat("   Wniosek:", ifelse(jb_test$p.value > 0.05, 
                         "Nie ma podstaw do odrzucenia H0 - reszty są normalne",
                         "Odrzucamy H0 - reszty nie są normalne"), "\n\n")
```

### Wykresy normalności

```{r, echo=FALSE}

par(mfrow = c(2, 2))
hist(residuals_model, breaks = 20, prob = TRUE, main = "Histogram reszt", 
     xlab = "Reszty", ylab = "Gęstość")
lines(density(residuals_model), col = "red", lwd = 2)
curve(dnorm(x, mean = mean(residuals_model), sd = sd(residuals_model)), 
      add = TRUE, col = "blue", lwd = 2)
legend("topright", c("Rzeczywista", "Teoretyczna"), col = c("red", "blue"), lwd = 2)

qqnorm(residuals_model,
       main = "Wykres Q-Q reszt",
       xlab = "Kwantyle teoretyczne",
       ylab = "Kwantyle próbkowe")    
qqline(residuals_model, col = "red")

```

## Testowanie autokorealcji

```{r, echo=FALSE}
cat("TEORIA: Autokorelacja oznacza korelację między resztami w różnych okresach.\n")
cat("H0: Brak autokorelacji reszt\n")
cat("H1: Występuje autokorelacja reszt\n\n")

```

### Test Durbina-Watsona

```{r, echo=FALSE}

dw_test <- durbinWatsonTest(model)
cat("1. TEST DURBINA-WATSONA:\n")
cat("   Statystyka DW =", round(dw_test$dw, 4), "\n")
cat("   p-value =", round(dw_test$p, 4), "\n")
cat("   Wniosek:", ifelse(dw_test$p > 0.05, 
                         "Nie ma podstaw do odrzucenia H0 - brak autokorelacji",
                         "Odrzucamy H0 - występuje autokorelacja"), "\n\n")
```

### Test Ljunga-Boxa

```{r, echo=FALSE}

ljung_test <- Box.test(residuals_model, lag = min(10, floor(n_obs/5)), type = "Ljung-Box")
cat("2. TEST LJUNGA-BOXA:\n")
cat("   Statystyka LB =", round(ljung_test$statistic, 4), "\n")
cat("   p-value =", round(ljung_test$p.value, 4), "\n")
cat("   Wniosek:", ifelse(ljung_test$p.value > 0.05, 
                         "Nie ma podstaw do odrzucenia H0 - brak autokorelacji",
                         "Odrzucamy H0 - występuje autokorelacja"), "\n\n")
```

### Test Breuscha-Godfreya

```{r, echo=FALSE}

bg_test <- bgtest(model, order = 2)
cat("3. TEST BREUSCHA-GODFREYA:\n")
cat("   Statystyka LM =", round(bg_test$statistic, 4), "\n")
cat("   p-value =", round(bg_test$p.value, 4), "\n")
cat("   Wniosek:", ifelse(bg_test$p.value > 0.05, 
                         "Nie ma podstaw do odrzucenia H0 - brak autokorelacji",
                         "Odrzucamy H0 - występuje autokorelacja"), "\n\n")
```

### Wykres autokorelacji

```{r, echo=FALSE}

acf(residuals_model, main = "Funkcja autokorelacji reszt", lag.max = 20)

```

## Badanie heteroskedastyczności

```{r, echo=FALSE}
cat("TEORIA: Heteroskedastyczność oznacza niestałą wariancję składnika losowego.\n")
cat("H0: Homoskedastyczność (stała wariancja)\n")
cat("H1: Heteroskedastyczność (niestała wariancja)\n\n")
```

### Test Breuscha-Pagana

```{r, echo=FALSE}

bp_test <- bptest(model)
cat("1. TEST BREUSCHA-PAGANA:\n")
cat("   Statystyka BP =", round(bp_test$statistic, 4), "\n")
cat("   p-value =", round(bp_test$p.value, 4), "\n")
cat("   Wniosek:", ifelse(bp_test$p.value > 0.05, 
                         "Nie ma podstaw do odrzucenia H0 - homoskedastyczność",
                         "Odrzucamy H0 - heteroskedastyczność"), "\n\n")
```

### Test White

```{r, echo=FALSE}
#white_test <- bptest(model, ~ fitted(model) + I(fitted(model)^2))
#cat("   Statystyka White =", round(white_test$statistic, 4), "\n")
#cat("   p-value =", round(white_test$p.value, 4), "\n")
#cat("   Wniosek:", ifelse(white_test$p.value > 0.05, 
#                        "Nie ma podstaw do odrzucenia H0 - homoskedastyczność",
#                         "Odrzucamy H0 - heteroskedastyczność"), "\n\n")
```

### Test Goldfelda-Quandta

```{r, echo=FALSE}
gq_test <- gqtest(model, order.by = fitted(model))
cat("   Statystyka GQ =", round(gq_test$statistic, 4), "\n")
cat("   p-value =", round(gq_test$p.value, 4), "\n")
cat("   Wniosek:", ifelse(gq_test$p.value > 0.05, 
                         "Nie ma podstaw do odrzucenia H0 - homoskedastyczność",
                         "Odrzucamy H0 - heteroskedastyczność"), "\n\n")
```

### Wykresy heteroskedastyczności

```{r, echo=FALSE}
par(mfrow = c(2, 2))
plot(fitted_values, residuals_model, main = "Reszty vs Wartości dopasowane", 
     xlab = "Wartości dopasowane", ylab = "Reszty")
abline(h = 0, col = "red")

plot(fitted_values, abs(residuals_model), main = "|Reszty| vs Wartości dopasowane", 
     xlab = "Wartości dopasowane", ylab = "|Reszty|")
```

## Testowanie współliniowości

### Test VIF

```{r, echo=FALSE}

cat("TEORIA: Współliniowość oznacza wysoką korelację między zmiennymi objaśniającymi.\n")
cat("VIF > 10: poważna współliniowość\n")
cat("VIF > 5: umiarkowana współliniowość\n")
cat("VIF < 5: brak problemów ze współliniowością\n\n")

  vif_values <- vif(model)
  cat("WSPÓŁCZYNNIKI VIF:\n")
  for(i in 1:length(vif_values)) {
    cat("  ", names(vif_values)[i], ":", round(vif_values[i], 3))
    if(vif_values[i] > 10) {
      cat(" *** POWAŻNA WSPÓŁLINIOWOŚĆ ***")
    } else if(vif_values[i] > 5) {
      cat(" ** UMIARKOWANA WSPÓŁLINIOWOŚĆ **")
    } else {
      cat(" - OK")
    }
    cat("\n")
  }
  
  max_vif <- max(vif_values)
  cat("\nWNIOSEK:", ifelse(max_vif < 5, "Brak problemów ze współliniowością",
                          ifelse(max_vif < 10, "Umiarkowana współliniowość - rozważ usunięcie zmiennej",
                                 "Poważna współliniowość - koniecznie usuń zmienną")), "\n")

```

## Testowanie stabilności parametrów

### Test Chowa

```{r, echo=FALSE}
cat("TEORIA: Test Chowa sprawdza czy parametry modelu są stabilne w czasie.\n")
cat("H0: Parametry są stabilne (brak przełomu strukturalnego)\n")
cat("H1: Parametry nie są stabilne (występuje przełom strukturalny)\n\n")

# Punkt przełomu w środku próby
breakpoint <- floor(n_obs / 2)

# Test Chowa
chow_test <- sctest(formula_modelu, data = data_stationary, type = "Chow", point = breakpoint)
cat("TEST CHOWA (punkt przełomu w obserwacji", breakpoint, "):\n")
cat("   Statystyka F =", round(chow_test$statistic, 4), "\n")
cat("   p-value =", round(chow_test$p.value, 4), "\n")
cat("   Wniosek:", ifelse(chow_test$p.value > 0.05, 
                         "Nie ma podstaw do odrzucenia H0 - parametry są stabilne",
                         "Odrzucamy H0 - brak stabilności parametrów"), "\n\n")
```

### Test CUSUM

```{r, echo=FALSE}
cusum_test <- efp(formula_modelu, data = data_stationary, type = "Rec-CUSUM")
plot(cusum_test, main = "Test CUSUM stabilności parametrów")

```

## Testowanie stabilności postaci analitycznej

### Test RESET Ramseya

```{r, echo=FALSE}
cat("TEORIA: Test RESET sprawdza czy postać funkcyjna modelu jest poprawna.\n")
cat("H0: Model ma poprawną postać funkcyjną\n")
cat("H1: Model ma niepoprawną postać funkcyjną\n\n")

reset_test <- resettest(model, power = 2:3, type = "fitted")
cat("1. TEST RESET RAMSEYA:\n")
cat("   Statystyka F =", round(reset_test$statistic, 4), "\n")
cat("   p-value =", round(reset_test$p.value, 4), "\n")
cat("   Wniosek:", ifelse(reset_test$p.value > 0.05, 
                         "Nie ma podstaw do odrzucenia H0 - poprawna postać modelu",
                         "Odrzucamy H0 - niepoprawna postać modelu"), "\n\n")
```

### Test liczby serii (runs test)

```{r , echo=FALSE}
cat("TEORIA: Test sprawdza czy reszty są losowo rozłożone.\n")
cat("H0: Reszty są losowo rozłożone\n")
cat("H1: Reszty wykazują systematyczne wzorce\n\n")

# Przekształć reszty na znaki (+ lub -)
signs <- ifelse(residuals_model > 0, 1, 0)
runs_test <- runs.test(as.factor(signs))
cat("   Statystyka =", round(runs_test$statistic, 4), "\n")
cat("   p-value =", round(runs_test$p.value, 4), "\n")
cat("   Wniosek:", ifelse(runs_test$p.value > 0.05, 
                         "Nie ma podstaw do odrzucenia H0 - reszty są losowe",
                         "Odrzucamy H0 - reszty wykazują wzorce"), "\n\n")

```

## Badanie efektu katalizy

### Test F

```{r , echo=FALSE}
cat("TEORIA: Efekt katalizy - jedna zmienna wpływa na siłę oddziaływania innej.\n")
cat("Sprawdzamy czy interakcje między zmiennymi są istotne.\n\n")

  # Model z interakcjami
  interaction_vars <- paste(best_hellwig_vars, collapse = " * ")
  formula_interaction <- as.formula(paste("D_CLOSE ~", interaction_vars))
  model_interaction <- lm(formula_interaction, data = data_stationary)
  
  # Test F dla istotności interakcji
  anova_result <- anova(model, model_interaction)
  cat("TEST F DLA INTERAKCJI:\n")
  cat("   Statystyka F =", round(anova_result$F[2], 4), "\n")
  cat("   p-value =", round(anova_result$`Pr(>F)`[2], 4), "\n")
  cat("   Wniosek:", ifelse(anova_result$`Pr(>F)`[2] > 0.05, 
                           "Brak istotnego efektu katalizy",
                           "Występuje istotny efekt katalizy"), "\n\n")
  
  # Wyświetl współczynniki interakcji
  cat("WSPÓŁCZYNNIKI INTERAKCJI:\n")
  interaction_summary <- summary(model_interaction)
  coef_table <- interaction_summary$coefficients
  interaction_terms <- rownames(coef_table)[grep(":", rownames(coef_table))]
  
  if(length(interaction_terms) > 0) {
    for(term in interaction_terms) {
      p_val <- coef_table[term, "Pr(>|t|)"]
      cat("  ", term, ": p-value =", round(p_val, 4))
      if(p_val < 0.05) cat(" ***")
      else if(p_val < 0.1) cat(" *")
      cat("\n")
    }
  }
 
```

## Badanie koincydencji

### Porównanie R²

```{r , echo=FALSE}
cat("TEORIA: Koincydencja - zmienna objaśniająca ma wpływ jedynie w określonych okresach.\n")
cat("Sprawdzamy stabilność parametrów w różnych podokresach.\n\n")

# Podział próby na tercyle
tercile_1 <- floor(n_obs / 3)
tercile_2 <- floor(2 * n_obs / 3)

# Modele dla podokresów
data_1 <- data_stationary[1:tercile_1, ]
data_2 <- data_stationary[(tercile_1+1):tercile_2, ]
data_3 <- data_stationary[(tercile_2+1):n_obs, ]

model_1 <- lm(formula_modelu, data = data_1)
model_2 <- lm(formula_modelu, data = data_2)
model_3 <- lm(formula_modelu, data = data_3)

cat("ANALIZA STABILNOŚCI PARAMETRÓW W PODOKRESACH:\n\n")


cat("Współczynniki determinacji:\n")
cat("  Okres 1 (obs. 1-", tercile_1, "): R² =", round(summary(model_1)$r.squared, 4), "\n")
cat("  Okres 2 (obs.", tercile_1+1, "-", tercile_2, "): R² =", round(summary(model_2)$r.squared, 4), "\n")
cat("  Okres 3 (obs.", tercile_2+1, "-", n_obs, "): R² =", round(summary(model_3)$r.squared, 4), "\n\n")

# Porównanie parametrów
cat("PORÓWNANIE PARAMETRÓW W PODOKRESACH:\n")
coef_1 <- coef(model_1)
coef_2 <- coef(model_2)
coef_3 <- coef(model_3)

for(param in names(coef_1)) {
  cat("Parametr", param, ":\n")
  cat("  Okres 1:", round(coef_1[param], 4), "\n")
  cat("  Okres 2:", round(coef_2[param], 4), "\n")
  cat("  Okres 3:", round(coef_3[param], 4), "\n")
  
  # Sprawdź czy parametry znacząco się różnią
  diff_12 <- abs(coef_1[param] - coef_2[param])
  diff_23 <- abs(coef_2[param] - coef_3[param])
  diff_13 <- abs(coef_1[param] - coef_3[param])
  
  if(max(diff_12, diff_23, diff_13) > abs(coef_1[param]) * 0.5) {
    cat("  *** MOŻLIWA KOINCYDENCJA - duże różnice między okresami ***\n")
  }
  cat("\n")
}
```

# Podsumowanie wyników

```{r , echo=FALSE}
cat("WYNIKI TESTÓW DIAGNOSTYCZNYCH:\n\n")

# Zbierz wyniki testów
test_results <- data.frame(
  Test = c("Normalność (Jarque-Bera)", "Autokorelacja (Ljung-Box)", 
           "Heteroskedastyczność (Breusch-Pagan)", "Współliniowość (max VIF)",
           "Stabilność (Chow)", "Postać modelu (RESET)"),
  Statystyka = c(round(jb_test$statistic, 3), round(ljung_test$statistic, 3),
                round(bp_test$statistic, 3), ifelse(length(best_hellwig_vars) > 1, round(max(vif_values), 3), "N/A"),
                round(chow_test$statistic, 3), round(reset_test$statistic, 3)),
  p_value = c(round(jb_test$p.value, 3), round(ljung_test$p.value, 3),
             round(bp_test$p.value, 3), "N/A", round(chow_test$p.value, 3), round(reset_test$p.value, 3)),
  Wynik = c(ifelse(jb_test$p.value > 0.05, "SPEŁNIONE", "NIESPEŁNIONE"),
           ifelse(ljung_test$p.value > 0.05, "SPEŁNIONE", "NIESPEŁNIONE"),
           ifelse(bp_test$p.value > 0.05, "SPEŁNIONE", "NIESPEŁNIONE"),
           ifelse(length(best_hellwig_vars) > 1, ifelse(max(vif_values) < 5, "SPEŁNIONE", "NIESPEŁNIONE"), "SPEŁNIONE"),
           ifelse(chow_test$p.value > 0.05, "SPEŁNIONE", "NIESPEŁNIONE"),
           ifelse(reset_test$p.value > 0.05, "SPEŁNIONE", "NIESPEŁNIONE"))
)

print(test_results)

# Ogólna ocena modelu
failed_tests <- sum(test_results$Wynik == "NIESPEŁNIONE")
total_tests <- nrow(test_results)

cat("\n=== OGÓLNA OCENA MODELU ===\n")
cat("Spełnione założenia:", total_tests - failed_tests, "/", total_tests, "\n")
cat("Niespełnione założenia:", failed_tests, "/", total_tests, "\n\n")

if(failed_tests == 0) {
  cat("MODEL SPEŁNIA WSZYSTKIE PODSTAWOWE ZAŁOŻENIA\n")
} else if(failed_tests <= 2) {
  cat("MODEL SPEŁNIA WIĘKSZOŚĆ ZAŁOŻEŃ - wymagane drobne korekty\n")
} else {
  cat("MODEL WYMAGA ISTOTNYCH POPRAWEK - niespełnia kluczowych założeń\n")
}

cat("\n=== REKOMENDACJE ===\n")
if(jb_test$p.value <= 0.05) {
  cat("• Rozważ transformację zmiennych (logarytmowanie) ze względu na brak normalności reszt\n")
}
if(ljung_test$p.value <= 0.05) {
  cat("• Dodaj zmienne opóźnione lub rozważ model ARIMA ze względu na autokorelację\n")
}
if(bp_test$p.value <= 0.05) {
  cat("• Użyj robustnych błędów standardowych ze względu na heteroskedastyczność\n")
}
if(length(best_hellwig_vars) > 1 && max(vif_values) >= 5) {
  cat("• Usuń zmienne o wysokim VIF ze względu na współliniowość\n")
}
if(chow_test$p.value <= 0.05) {
  cat("• Rozważ model ze zmiennymi strukturalnymi ze względu na niestabilność parametrów\n")
}
if(reset_test$p.value <= 0.05) {
  cat("• Zmień postać funkcyjną modelu (dodaj nieliniowości)\n")
}

cat("\n", paste(rep("=", 60), collapse=""), "\n")
cat("KONIEC WERYFIKACJI MODELU\n")
cat(paste(rep("=", 60), collapse=""), "\n")
```




### TESTUWENCJA OD CHATA
```{r, echo=FALSE}
model_formula<-formula_modelu
model_lin<-model
data_prepared<-data_stationary
# 7. Analiza diagnostyczna
# 7.1 Normalność reszt
shapiro_lin <- shapiro.test(residuals(model_lin))

# 7.2 Autokorelacja reszt
dw_lin <- durbinWatsonTest(model_lin)
ljung_lin <- Box.test(residuals(model_lin), lag = 10, type = "Ljung-Box")

# 7.3 Heteroskedastyczność
bp_lin <- bptest(model_lin)
gq_lin <- gqtest(model_lin, order.by = fitted(model_lin))

# 7.4 Kollinearność (VIF)
vif_lin <- vif(model_lin)

# Wyświetlenie wyników diagnostyki
cat("=== TEST NORMALNOŚCI (Shapiro-Wilk) ===\n")
print(shapiro_lin)
cat("\n=== TEST AUTOKORELACJI (Durbin-Watson) ===\n")
print(dw_lin)
cat("\n=== TEST AUTOKORELACJI (Ljung-Box) ===\n")
print(ljung_lin)
cat("\n=== TEST HETEROSKEDASTYCZNOŚCI (Breusch-Pagan) ===\n")
print(bp_lin)
cat("\n=== TEST HETEROSKEDASTYCZNOŚCI (Goldfeld-Quandt) ===\n")
print(gq_lin)
cat("\n=== WSPÓŁCZYNNIKI VIF ===\n")
print(vif_lin)

# 8. Jeśli heteroskedastyczność występuje, stosujemy odporne błędy standardowe
cat("\n=== Estymacja z odmianą HC1 (robust SE) ===\n")
robust_coefs <- coeftest(model_lin, vcov = vcovHC(model_lin, type = "HC1"))
print(robust_coefs)


# 11. Jeśli nadal heteroskedastyczność lub autokorelacja utrzymuje się, można rozważyć dodanie opóźnień w formule:
# model_formula_ar_lags <- as.formula("D_log_CLOSE ~ D_log_WIG20 + D_PMI + D_log_OIL + D2_S.P500 +
#                                      lag(D_log_CLOSE, 1) + lag(D_log_CLOSE, 2)")
# model_lagged <- lm(model_formula_ar_lags, data = data_prepared)
# summary(model_lagged)

# 12. Jeśli test RESET wskazuje na niepoprawną postać funkcji, dodajemy wielomiany lub interakcje:
reset_lin <- resettest(model_lin, power = 2:3, type = "fitted")
cat("\n=== TEST RESET RAMSEYA DLA MODEL_LIN ===\n")
print(reset_lin)

# W razie potrzeby, model wzbogacamy np. o interakcję:
# model_interaction <- lm(D_log_CLOSE ~ D_log_WIG20 * D_PMI + D_log_OIL + D2_S.P500, data = data_prepared)
# summary(model_interaction)

# 13. Finalnie wyświetlamy porównanie R² i VIF, by upewnić się, że model jest stabilny
cat("\n=== Podsumowanie modelu linowego ===\n")
cat("R^2:", round(summary(model_lin)$r.squared, 4), "\n")
cat("Adj. R^2:", round(summary(model_lin)$adj.r.squared, 4), "\n")
cat("Maksymalny VIF:", round(max(vif_lin), 3), "\n")

# Rekomendacje na podstawie wyników
cat("\n=== REKOMENDACJE ===\n")
if(shapiro_lin$p.value <= 0.05) {
  cat("• Brak normalności reszt – rozważ transformację zmiennej (log-diff) lub usunięcie outlierów.\n")
}
if(dw_lin$p <= 0.05 | ljung_lin$p.value <= 0.05) {
  cat("• Autokorelacja reszt – rozważ model GLS(AR1) lub dodanie opóźnień w zmiennych objaśniających.\n")
}
if(bp_lin$p.value <= 0.05 | gq_lin$p.value <= 0.05) {
  cat("• Heteroskedastyczność – zastosuj odporne błędy standardowe (robust SE) lub model GARCH.\n")
}
if(max_vif >= 5) {
  cat("• Współliniowość – usuń lub połącz zmienne o wysokim VIF.\n")
}
if(reset_lin$p.value <= 0.05) {
  cat("• Niepoprawna postać funkcyjna – spróbuj dodać składniki nieliniowe lub interakcje.\n")
}
```











### TESTUWENCJA

## OCENA ISTOTNOŚCI ZMIENNYCH

### Test t-Studenta dla poszczególnych parametrów
```{r, echo=FALSE}



cat("H0: βi = 0 (parametr nie jest istotny statystycznie)\n")
cat("H1: βi ≠ 0 (parametr jest istotny statystycznie)\n")
cat("Poziom istotności: α = 0.05\n\n")

# Podsumowanie modelu
model_summary <- summary(model)
print(model_summary)

# Szczegółowa analiza każdego parametru
coefficients_df <- as.data.frame(model_summary$coefficients)
coefficients_df$Variable <- rownames(coefficients_df)
coefficients_df$Significance <- ifelse(coefficients_df$`Pr(>|t|)` < 0.001, "***",
                                     ifelse(coefficients_df$`Pr(>|t|)` < 0.01, "**",
                                           ifelse(coefficients_df$`Pr(>|t|)` < 0.05, "*",
                                                 ifelse(coefficients_df$`Pr(>|t|)` < 0.1, ".", ""))))

cat("\nTABELA WYNIKÓW TESTÓW t-STUDENTA:\n")
cat("================================================================\n")
for(i in 1:nrow(coefficients_df)) {
  var_name <- coefficients_df$Variable[i]
  estimate <- round(coefficients_df$Estimate[i], 6)
  std_error <- round(coefficients_df$`Std. Error`[i], 6)
  t_value <- round(coefficients_df$`t value`[i], 4)
  p_value <- coefficients_df$`Pr(>|t|)`[i]
  significance <- coefficients_df$Significance[i]
  
  cat("Zmienna:", var_name, "\n")
  cat("  Współczynnik:", estimate, "\n")
  cat("  Błąd standardowy:", std_error, "\n")
  cat("  Statystyka t:", t_value, "\n")
  cat("  p-value:", if(p_value < 0.001) "< 0.001" else round(p_value, 4), "\n")
  cat("  Istotność:", significance, "\n")
  cat("  Wniosek:", ifelse(p_value < 0.05, 
                          "PARAMETR ISTOTNY STATYSTYCZNIE", 
                          "PARAMETR NIEISTOTNY STATYSTYCZNIE"), "\n")
}
```

### Test Walda (test łącznej istotności)

```{r, echo=FALSE}
cat("\n1.2 TEST WALDA (ŁĄCZNA ISTOTNOŚĆ ZMIENNYCH)\n")
cat("----------------------------------------------------------------\n")
cat("H0: β1 = β2 = β3 = 0 (wszystkie parametry strukturalne równe zero)\n")
cat("H1: co najmniej jeden βi ≠ 0\n")
cat("Poziom istotności: α = 0.05\n\n")

# Test F całkowitej istotności modelu
f_statistic <- model_summary$fstatistic
f_value <- f_statistic[1]
f_df1 <- f_statistic[2]
f_df2 <- f_statistic[3]
f_p_value <- pf(f_value, f_df1, f_df2, lower.tail = FALSE)

cat("WYNIKI TESTU WALDA (Test F):\n")
cat("Statystyka F:", round(f_value, 4), "\n")
cat("Stopnie swobody:", f_df1, "i", f_df2, "\n")
cat("p-value:", if(f_p_value < 0.001) "< 0.001" else round(f_p_value, 6), "\n")
cat("Wniosek:", ifelse(f_p_value < 0.05, 
                     "ODRZUCAMY H0 - model jako całość jest istotny statystycznie",
                     "NIE MA PODSTAW DO ODRZUCENIA H0 - model nieistotny"), "\n\n")

# Test Walda dla wybranych ograniczeń (alternatywna implementacja)
if(length(coef(model)) > 2) {  # jeśli mamy więcej niż tylko wyraz wolny
  wald_test <- linearHypothesis(model, names(coef(model))[-1])
  cat("ALTERNATYWNY TEST WALDA (linearHypothesis):\n")
  print(wald_test)
}
```


## OCENA WSPÓŁCZYNNIKA DETERMINACJI

### WSPÓŁCZYNNIKI DETERMINACJI R²

```{r, echo=FALSE}
# Podstawowe statystyki modelu
r_squared <- model_summary$r.squared
adj_r_squared <- model_summary$adj.r.squared
n_obs <- nobs(model)
n_params <- length(coef(model))
degrees_freedom <- model_summary$df[2]

cat("WSPÓŁCZYNNIKI DETERMINACJI:\n")
cat("----------------------------------------------------------------\n")
cat("R² (współczynnik determinacji):", round(r_squared, 4), "\n")
cat("R²_adj (skorygowany współczynnik determinacji):", round(adj_r_squared, 4), "\n")
cat("Liczba obserwacji:", n_obs, "\n")
cat("Liczba parametrów:", n_params, "\n")
cat("Stopnie swobody:", degrees_freedom, "\n\n")

# Interpretacja R²
cat("INTERPRETACJA R²:\n")
cat("----------------------------------------------------------------\n")
cat("Model wyjaśnia", round(r_squared * 100, 2), "% zmienności zmiennej D_CLOSE\n")
cat("Po skorygowaniu o liczbę zmiennych:", round(adj_r_squared * 100, 2), "%\n\n")

# Ocena jakości modelu
quality_assessment <- if(r_squared > 0.8) {
  "BARDZO DOBRY MODEL"
} else if(r_squared > 0.6) {
  "DOBRY MODEL"
} else if(r_squared > 0.4) {
  "ZADOWALAJĄCY MODEL"
} else {
  "SŁABY MODEL"
}

cat("OCENA JAKOŚCI MODELU:", quality_assessment, "\n\n")

# Dodatkowe statystyki
residual_std_error <- model_summary$sigma
cat("DODATKOWE STATYSTYKI:\n")
cat("----------------------------------------------------------------\n")
cat("Standardowy błąd reszt:", round(residual_std_error, 6), "\n")

# Obliczenie sum kwadratów
y_actual <- model$model[,1]  # zmienna objaśniana
y_fitted <- fitted(model)    # wartości dopasowane
y_mean <- mean(y_actual)     # średnia zmiennej objaśnianej

SST <- sum((y_actual - y_mean)^2)      # całkowita suma kwadratów
SSE <- sum(residuals(model)^2)         # suma kwadratów reszt
SSR <- sum((y_fitted - y_mean)^2)      # suma kwadratów regresji

cat("SST (całkowita suma kwadratów):", round(SST, 4), "\n")
cat("SSR (suma kwadratów regresji):", round(SSR, 4), "\n")
cat("SSE (suma kwadratów reszt):", round(SSE, 4), "\n")
cat("Sprawdzenie: SST = SSR + SSE =", round(SSR + SSE, 4), "\n\n")
```


## INTERPRETACJA PARAMETRÓW MODELU


```{r, echo=FALSE}
cat("================================================================================\n")
cat("3. INTERPRETACJA PARAMETRÓW MODELU\n")
cat("================================================================================\n\n")

cat("OSTATECZNA POSTAĆ MODELU:\n")
cat("----------------------------------------------------------------\n")

# Utworzenie równania modelu
coeffs <- coef(model)
equation <- "D_CLOSE = "

for(i in 1:length(coeffs)) {
  if(i == 1) {
    equation <- paste0(equation, round(coeffs[i], 6))
  } else {
    sign <- if(coeffs[i] >= 0) " + " else " - "
    equation <- paste0(equation, sign, abs(round(coeffs[i], 6)), " × ", names(coeffs)[i])
  }
}
equation <- paste0(equation, " + ε")

cat(equation, "\n\n")

# Interpretacja każdego parametru
cat("INTERPRETACJA PARAMETRÓW:\n")
cat("----------------------------------------------------------------\n\n")

param_names <- names(coeffs)
param_values <- as.numeric(coeffs)
param_pvalues <- coefficients_df$`Pr(>|t|)`

for(i in 1:length(coeffs)) {
  param_name <- param_names[i]
  param_value <- param_values[i]
  p_val <- param_pvalues[i]
  is_significant <- p_val < 0.05
  
  cat("PARAMETR:", param_name, "\n")
  cat("Wartość:", round(param_value, 6), "\n")
  cat("Istotność statystyczna:", ifelse(is_significant, "ISTOTNY", "NIEISTOTNY"), 
      "(p =", round(p_val, 4), ")\n")
  
  if(param_name == "(Intercept)") {
    cat("Interpretacja: Wyraz wolny - średnia wartość D_CLOSE gdy wszystkie\n")
    cat("              zmienne objaśniające przyjmują wartość zero.\n")
  } else if(param_name == "D_PMI") {
    cat("Interpretacja: Wzrost wskaźnika PMI o 1 p.p. (w ujęciu pierwszej różnicy)\n")
    cat("              powoduje", ifelse(param_value > 0, "wzrost", "spadek"), 
        "rentowności obligacji o", abs(round(param_value, 6)), "p.p., ceteris paribus.\n")
    cat("Uzasadnienie: PMI odzwierciedla aktywność przemysłową - wzrost może\n")
    cat("              sygnalizować ożywienie gospodarcze i oczekiwania wyższych stóp.\n")
  } else if(param_name == "D_WIG20") {
    cat("Interpretacja: Wzrost indeksu WIG20 o 1 punkt (w ujęciu pierwszej różnicy)\n")
    cat("              powoduje", ifelse(param_value > 0, "wzrost", "spadek"), 
        "rentowności obligacji o", abs(round(param_value, 6)), "p.p., ceteris paribus.\n")
    cat("Uzasadnienie: Relacja między rynkiem akcji a rynkiem obligacji -\n")
    cat("              przepływ kapitału między rynkami.\n")
  } else if(param_name == "D2_OIL") {
    cat("Interpretacja: Zmiana w drugiej różnicy ceny ropy o 1 USD/baryłka\n")
    cat("              powoduje", ifelse(param_value > 0, "wzrost", "spadek"), 
        "rentowności obligacji o", abs(round(param_value, 6)), "p.p., ceteris paribus.\n")
    cat("Uzasadnienie: Ceny ropy wpływają na inflację - wzrost może zwiększać\n")
    cat("              oczekiwania inflacyjne i wyższe stopy procentowe.\n")
  }
  
  cat("Kierunek wpływu:", ifelse(param_value > 0, "DODATNI", "UJEMNY"), "\n")
  cat("Siła oddziaływania:", ifelse(abs(param_value) > 0.01, "SILNA", 
                                   ifelse(abs(param_value) > 0.001, "UMIARKOWANA", "SŁABA")), "\n")
  cat("----------------------------------------------------------------\n\n")
}
```

## PODSUMOWANIE OGÓLNE

```{r, echo=FALSE}


# Liczba istotnych parametrów
significant_params <- sum(param_pvalues < 0.05)
total_params <- length(param_pvalues)

cat("STATYSTYKI OGÓLNE:\n")
cat("----------------------------------------------------------------\n")
cat("Liczba parametrów istotnych statystycznie:", significant_params, "/", total_params, "\n")
cat("Procent wyjaśnionej zmienności:", round(r_squared * 100, 2), "%\n")
cat("Jakość dopasowania:", quality_assessment, "\n")
cat("Istotność modelu jako całości:", ifelse(f_p_value < 0.05, "ISTOTNY", "NIEISTOTNY"), "\n\n")

cat("WNIOSKI:\n")
cat("----------------------------------------------------------------\n")

if(f_p_value < 0.05) {
  cat("✓ Model jako całość jest istotny statystycznie\n")
} else {
  cat("✗ Model jako całość nie jest istotny statystycznie\n")
}

if(r_squared > 0.5) {
  cat("✓ Model wykazuje zadowalający poziom dopasowania\n")
} else {
  cat("✗ Model wykazuje słabe dopasowanie\n")
}

if(significant_params > total_params/2) {
  cat("Większość parametrów jest istotna statystycznie\n")
} else {
  cat("✗ Większość parametrów nie jest istotna statystycznie\n")
}

cat("\nREKOMENDACJE:\n")
cat("----------------------------------------------------------------\n")

if(significant_params < total_params) {
  cat("• Rozważ usunięcie nieistotnych zmiennych z modelu\n")
}

if(r_squared < 0.6) {
  cat("• Rozważ dodanie dodatkowych zmiennych objaśniających\n")
  cat("• Sprawdź czy nie pominięto istotnych zmiennych\n")
}

cat("• Przeprowadź testy diagnostyczne (normalność, autokorelacja, heteroskedastyczność)\n")
cat("• Sprawdź stabilność parametrów w czasie\n")

```
