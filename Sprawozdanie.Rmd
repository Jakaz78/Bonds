---
title: "Sprawozdanie"
author: "Jakub Kaźmierczyk"
date: "`r Sys.Date()`"
output:
  pdf_document:
    toc: true
    toc_depth: 4 
    number_sections: true
    latex_engine: xelatex
    highlight: tango
fontsize: 11pt
mainfont: "Times New Roman"
geometry: margin=2.5cm
linestretch: 1.5
lang: "pl"
header-includes:
  - \renewcommand{\contentsname}{Spis treści}
  - \usepackage{fancyhdr}
  - \pagestyle{fancy}
  - \fancyhf{}
  - \cfoot{\thepage}
---

# Wprowadzenie

## Opis projektu

Projekt ma na celu budowę kompleksowego modelu ekonometrycznego służącego do analizy i prognozowania rentowności 10-letnich polskich obligacji skarbowych. Model zostanie zbudowany na podstawie szeregów czasowych, co umożliwia głębszą analizę dynamicznych zależności ekonomicznych.

## Zmienne

### Zmienna objaśniana

**CLOSE** - rentowność 10-letnich polskich obligacji skarbowych

### Zmienne objaśniające

**10YDEBOND** - rentowność 10-letnich niemieckich obligacji skarbowych\
**10YUSBOND** - rentowność 10-letnich amerykańskich obligacji skarbowych\
**DETAL** - sprzedaż detaliczna miesiąc do miesiąca\
**XAUUSD** - cena złota w dolarze amerykańskim\
**S&P500** - ETF 500 największych notowanych na giełdzie amerykańskich spółek\
**PMI** - wskaźnik aktywności przemysłowej\
**WIG20** - 20 największych notowanych na giełdzie polskich spółek\
**OIL** - cena ropy naftowej za baryłkę\
**UNEMPLOYMENT** - stopa bezrobocia w Polsce\
**USDPLN** - kurs dolara amerykańskiego wyrażony w złotych\
**INFLATION** - inflacja rok do roku\
**WIBOR** - referencyjna stopa procentowa dla polskiego rynku międzybankowego\

## Źródła

[www.stooq.com](https://stooq.pl)\

\newpage

# Wczytywanie danych

Dane pochodzą ze strony www.stooq.com. Zawierają dane dotyczące zmiennych od czerwca 1999 do czerwca 2025, w interwale miesięcznym

```{r setup, echo=FALSE, warning=FALSE, message = FALSE}
library(corrplot)
library(readxl)
library(tinytex)
library(ggcorrplot)
library(urca)      
library(tseries)   
library(ggplot2)   
library(dplyr)     
library(tidyr)
library(zoo)
library(gridExtra)
library(grid)
library(lmtest)       
library(car)          
library(nortest)    
library(sandwich)     
library(strucchange)  
library(nlme)
library(forecast)

```

```{r}
data_all <- read_excel("data.xlsx")
data_all <- data_all[, -c(1, 3, 4)]

data_all[] <- lapply(data_all, function(col) {
  na.approx(col, na.rm = FALSE)
})


n <- nrow(data_all)
train_size <- floor(0.8 * n)

data <- data_all[1:train_size, , drop = FALSE]
data_test  <- data_all[(train_size + 1):n, , drop = FALSE]

Y <- data["CLOSE"]
X <- data[, !names(data) %in% "CLOSE", drop = FALSE]
```

\newpage

# Podstawowe statystyki

## Zmienna objaśniana

```{r , echo=FALSE}
summary(Y)
```

Mediana rentowności 10-letnich polskich obligacji wynosi około 5,495 %, podczas gdy średnia to 5,610 %. Różnica mediana–średnia (5,495 vs 5,610) wskazuje niewielką prawą skośność rozkładu.

Minimalna zaobserwowana wartość to 1,843 %, a maksymalna aż 13,288 %. Zakres rozpiętości (13,288 – 1,843 = 11,445 punktu procentowego) jest stosunkowo szeroki, co sugeruje, że w okresie badanym zdarzały się uderzeniowe wahania rentowności.

Pierwszy kwartyl (3,457 %) i trzeci kwartyl (6,269 %) pokazują, że połowa obserwacji mieści się w zakresie od 3,457 % do 6,269 %. To oznacza, że większość wartości koncentruje się wokół poziomu 5 %–6 %.

## Zmienne objaśniające

```{r , echo=FALSE}
summary(X)
```

## Macierze korelacji

### Macierz korelacji przed usunięciem zmiennych

```{r corrplot, fig.width=20, fig.height=20, echo=FALSE}
cor_matrix <- cor(data, use = "pairwise.complete.obs", method = "pearson")


    corrplot(cor_matrix, method = "color",
           order = "alphabet",
           addCoef.col = "black", 
           tl.col = "black", tl.cex = 2.5, cl.cex = 2.5, number.cex=2.6)
```

Z 11 zmiennych objaśniających wybrałem 7, których wartość bezwzględna korelacji nie przekracza 0,8. Dodatkowo usuwam zmienną "INFLATION" abym mógł zlogarytmować dane.

\newpage

### Macierz korlelacji po usunięciu zmiennych

```{r corrplot2, fig.width=20, fig.height=20, echo=FALSE}
data <- data[, !(colnames(data) %in% c("XAUUSD","WIBOR","10YDEBOND","10YUSBOND","DETAL","USDPLN","INFLATION"))]
data_test <- data_test[, !(colnames(data_test) %in% c("XAUUSD","WIBOR","10YDEBOND","10YUSBOND","DETAL","USDPLN","INFLATION","UNEMPLOYMENT","PMI","S&P500"))]
data <- data[1:train_size, , drop = FALSE]



cor_matrix <- cor(data, use = "pairwise.complete.obs", method = "pearson")


    corrplot(cor_matrix, method = "color",
           order = "alphabet",
           addCoef.col = "black", 
           tl.col = "black", tl.cex = 2.5, cl.cex = 2.5, number.cex=2.6)
```

### Logarytmowanie danych

```{r}
data<-log(data)
data_test<-log(data_test)
```

\newpage

# Identyfikacja niestacjonarnych zmiennych objaśniających

```{r analiza_stacjonarnosci, warning=FALSE, message=FALSE, echo=FALSE}

check_stationarity <- function(x) {
  adf_test <- ur.df(x, type = "trend")@teststat[1] < ur.df(x, type = "trend")@cval[1,"5pct"]
  kpss_test <- kpss.test(x)$p.value > 0.05
  return(adf_test & kpss_test)
}

non_stationary_vars <- c()
non_stationary_vars_test <- c()

for (var in colnames(data)) {
  series <- ts(data[[var]])
  if (!check_stationarity(series)) {
    non_stationary_vars <- c(non_stationary_vars, var)
  }
}

for (var in colnames(data_test)) {
  series <- ts(data_test[[var]])
  if (!check_stationarity(series)) {
    non_stationary_vars_test <- c(non_stationary_vars_test, var)
  }
}
```

## Sprawdzenie niestacjonarności zmiennych

```{r , echo=FALSE, comment=NA, warning=FALSE, message=FALSE}
stationarity_df <- data.frame(
  Zmienna = colnames(data),
  Stacjonarnosc = sapply(data, function(col) {
    if (check_stationarity(ts(col))) {
      return("Stacjonarna")
    } else {
      return("Niestacjonarna")
    }
  })
)


knitr::kable(stationarity_df, row.names = FALSE)

```

Wszystkie zmienne w pierwotnej postaci (zarówno CLOSE, jak i 5 zmiennych objaśniających: WIG20, S&P500, UNEMPLOYMENT, PMI, OIL) okazały się niestacjonarne (wyniki testów ADF wskazywały p-value \> 0,05 lub wartość statystyki testowej wyższa od wartości krytycznej; KPSS p-value \< 0,05).

Oznacza to, że w danych występuje wspólny trend lub efekt niestacjonarności, co skłania do zastosowania różnicowania, by usunąć jednostkowe pierwiastki i otrzymać procesy stacjonarne

## Usunięcie niestacjonarności

```{r usuwanie_niestacjonarnosci, message=FALSE, echo=FALSE, comment = NA }

dir.create("plots", showWarnings = FALSE)

remove_nonstationarity <- function(data, non_stationary_vars, max_diff = 2, 
                                   show_plots = TRUE, save_plots = FALSE, 
                                   plot_dir = "plots") {
  if (save_plots && !dir.exists(plot_dir)) {
    dir.create(plot_dir, recursive = TRUE)
  }

  transformed_data <- list()
  diff_info <- list()
  plots_before <- list()
  plots_after <- list()

  for (var_name in colnames(data)) {
    original_series <- data[[var_name]]
    current_series <- original_series
    order <- 0

    if (var_name %in% non_stationary_vars) {
      for (i in 1:max_diff) {
        test_series <- if (i == 0) original_series else diff(original_series, differences = i)

        if (check_stationarity(test_series)) {
         order <- i
         current_series <- test_series
         break
       }

        if (i == max_diff) {
          order <- max_diff
          current_series <- diff(original_series, differences = max_diff)
        }
      }
    }

   new_name <- if (order > 0) {
     paste0("D", if(order > 1) order else "", "_", var_name)} else {
     var_name
   }
   
   diff_info[[var_name]] <- list(order = order, name = new_name)
   transformed_data[[new_name]] <- current_series

    if (show_plots || save_plots) {
      df_plot_before <- data.frame(Index = 1:length(original_series), Value = as.numeric(original_series))
      df_plot_after  <- data.frame(Index = 1:length(current_series), Value = as.numeric(current_series))

      plot_before <- ggplot(df_plot_before, aes(x = Index, y = Value)) +
        geom_line(color = "blue", size = 0.7) +
        labs(title = paste("Przed:", var_name, "Liczba różnicowań: ",order), x = "Czas", y = "Wartość") +
        theme_minimal() +
        theme(plot.title = element_text(size = 10, face = "bold"))

      plot_after <- ggplot(df_plot_after, aes(x = Index, y = Value)) +
        geom_line(color = "red", size = 0.7) +
        labs(title = paste("Po:", new_name), x = "Czas", y = "Wartość") +
        theme_minimal() +
        theme(plot.title = element_text(size = 10, face = "bold"))

      plots_before[[var_name]] <- plot_before
      plots_after[[var_name]] <- plot_after

      if (save_plots) {
        ggsave(filename = file.path(plot_dir, paste0("before_", var_name, ".png")),
               plot = plot_before, width = 6, height = 4, dpi = 300)
        ggsave(filename = file.path(plot_dir, paste0("after_", new_name, ".png")),  
               plot = plot_after, width = 6, height = 4, dpi = 300)
      }
    }
    
  }

  max_diff_order <- max(sapply(diff_info, function(x) x$order))

  final_df <- as.data.frame(lapply(transformed_data, function(x) {
    c(rep(NA, max_diff_order), x)[1:(nrow(data) + max_diff_order)]
  }))
  final_df <- final_df[complete.cases(final_df), ]

  return(list(
    data = final_df,
    diff_info = diff_info,
    plots_before = plots_before,
    plots_after = plots_after
  ))
}

remove_nonstationarity_test <- function(data_test, diff_info) {
  transformed_data <- list()
  max_diff_order <- max(sapply(diff_info, function(x) x$order))

  for (var in names(diff_info)) {
    if (!var %in% colnames(data_test)) next
    order <- diff_info[[var]]$order
    newname <- diff_info[[var]]$name
    x <- data_test[[var]]

    if (order == 0) {
      transformed_data[[newname]] <- x
    } else {
      transformed_data[[newname]] <- diff(x, differences = order)
    }
  }

  final_df <- as.data.frame(lapply(transformed_data, function(x) {
    c(rep(NA, max_diff_order), x)[1:(nrow(data_test) + max_diff_order)]
  }))

  final_df <- final_df[complete.cases(final_df), ]
  return(final_df)
}
```

```{r wywołanie_funkcji, echo=FALSE, warning=FALSE, message=FALSE, comment=NA, fig.align='center', fig.width=10, fig.height=6}

non_stationary_vars <- c()

for (var in colnames(data)) {
  series <- ts(data[[var]])
  if (!check_stationarity(series)) {
    non_stationary_vars <- c(non_stationary_vars, var)
  }
}

result <- remove_nonstationarity(
  data,
  non_stationary_vars,
  save_plots = TRUE,
  show_plots = FALSE
)

data_stationary <- result$data
diff_info <- result$diff_info




```

## Ponowne sprawdzenie niestacjonarności zmiennych

```{r sprawdzenie_zmienncyh, echo=FALSE, warning=FALSE, message=FALSE, comment = NA}
stationarity_df <- data.frame(
  Zmienna = colnames(data_stationary),
  Stacjonarnosc = sapply(data_stationary, function(col) {
    if (check_stationarity(ts(col))) {
      return("Stacjonarna")
    } else {
      return("Niestacjonarna")
    }
  })
)


knitr::kable(stationarity_df, row.names = FALSE)
```

Wszystkie zmienne przekształcone do postaci różnicowej (D_CLOSE, D_WIG20, D2_S&P500, D_UNEMPLOYMENT, D_PMI, D_OIL) okazały się stacjonarne (test AD-Fuller zakończył się odrzuceniem hipotezy o istnieniu pierwiastka jednostkowego, a test KPSS nie wskazał na niestacjonarność).

Oznacza to, że proces różnicowania był wystarczający – w dalszej części modelu możemy bezpiecznie użyć tych stacjonarnych serii jako zmiennych w regresji liniowej.

## Sprawdzenie korelacji po usunięciu niestacjonarności

```{r, fig.width=20, fig.height=20, echo=FALSE}

cor_matrix <- cor(data_stationary, use = "pairwise.complete.obs", method = "pearson")


    corrplot(cor_matrix, method = "color",
           order = "alphabet",
           addCoef.col = "black", 
           tl.col = "black", tl.cex = 2.5, cl.cex = 2.5, number.cex=2.6)
```

## Usunięcie zmiennych o zerowej wariancji

### Przed usunięciem

```{r , echo=FALSE, warning=FALSE, message=FALSE, comment = NA}
for (col_name in colnames(data_stationary)) {
  
      col_cv <- sd(data_stationary[[col_name]]) / mean(data_stationary[[col_name]]) * 100
      col_var <- var(data_stationary[[col_name]])
      cat(col_name, "- Współczynnik zmienności:", col_cv, "%, Wariancja: ", col_var,"\n")
}



#usuwam zmienne o prawie 0 wariancji i helwwig spada

data_stationary <- data_stationary[, !(colnames(data_stationary) %in% c("D2_UNEMPLOYMENT"))]


```

Z uwagi na bardzo niską wariancję D_UNEMPLOYMENT zdecydowałem się usunąć tą zmienną, bo nie wnosi istotnej zmienności do zestawu predyktorów.

### Po usunięciu

```{r , echo=FALSE, warning=FALSE, message=FALSE, comment = NA}

for (col_name in colnames(data_stationary)) {
  
      col_cv <- sd(data_stationary[[col_name]]) / mean(data_stationary[[col_name]]) * 100
      col_var <- var(data_stationary[[col_name]])
      cat(col_name, "- Współczynnik zmienności:", col_cv, "%, Wariancja: ", col_var,"\n")
}
```

\newpage

# Metoda doboru zmiennych

## Metoda Hellwiga


```{r , echo=FALSE, warning=FALSE, message=FALSE, comment = NA}
hellwig_method_original <- function(y, X) {
  all_vars <- colnames(X)
  R <- cor(cbind(y, X))
  r0 <- R[-1, 1]        
  Rxx <- R[-1, -1]      
  results <- list()
  
  for (k in 1:length(all_vars)) {
    combos <- combn(all_vars, k, simplify = FALSE)
    
    for (combo in combos) {
      indices <- match(combo, all_vars)
      r0_sub <- r0[indices]
      Rxx_sub <- Rxx[indices, indices]
      
      h_kj <- numeric(length(indices))
      
      for (j in seq_along(indices)) {
        if (length(indices) == 1) {
          denom <- 1  
        } else {
          denom <- 1 + sum(abs(Rxx_sub[j, -j]))
        }
        h_kj[j] <- (r0_sub[j]^2) / denom
      }
      
      H_k <- sum(h_kj)
      results[[paste(combo, collapse = ", ")]] <- H_k
    }
  }
  
  df <- data.frame(
    Zmienne = names(results),
    Pojemnosc_Hellwiga = round(unlist(results), 4),
    row.names = NULL
  )
  
  df <- df[order(-df$Pojemnosc_Hellwiga), ]
  return(df)
}
X_stat <- data_stationary[, -1]         
Y_stat <- data_stationary["D_CLOSE"]    
hellwig_result <- hellwig_method_original(Y_stat, X_stat)
```

```{r, echo=FALSE, warning=FALSE, message=NA, comment = NA}
najlepsza_kombinacja_string <- hellwig_result$Zmienne[1]
best_hellwig_vars <- unlist(strsplit(najlepsza_kombinacja_string, ", "))
cat("Zmienne składowe w najlepszej kombinacji:\n")
for (zmienna in best_hellwig_vars) {
  writeLines(zmienna)
}
cat("Pojemność Hellwiga dla tej kombinacji:", hellwig_result$Pojemnosc_Hellwiga[1], "\n")

zmienne_objaśniające_do_modelu <- unlist(strsplit(najlepsza_kombinacja_string, ", "))

cols_to_keep <- c(best_hellwig_vars, "D_CLOSE")
data_stationary <- data_stationary[, cols_to_keep]

data_test_stationary <- remove_nonstationarity_test(data_test, diff_info)


data_test_stationary <- data_test_stationary[, cols_to_keep]
```

Wybrałem Metodę Hellwiga, ponieważ pozwala ona wybrać taki zestaw predyktorów, który maksymalizuje korelację z rentownością obligacji (D_CLOSE) przy jednoczesnym minimalizowaniu wzajemnej korelacji między zmiennymi. Dzięki temu uzyskałem prosty, ale informacyjnie optymalny model oparty na D_WIG20 i D_OIL.

\newpage

# Tworzenie modelu ekonometrycznego

```{r message=FALSE, comment=NA, echo=FALSE}

formula_modelu <- reformulate(best_hellwig_vars, response = "D_CLOSE")

model <- lm(formula_modelu, data = data_stationary)

print(summary(model))
```

Statystyka F = 14,42 (df = 2 i 243), p-value ≈ 1,211×10⁻⁶. Oznacza to, że jako całość model jest istotny statystycznie – przynajmniej jedna ze zmiennych objaśniających przyczynia się do wyjaśnienia zmienności D_CLOSE

R-kwadrat: 0,1061 → model wyjaśnia tylko około 10,61 % zmienności zmiennej D_CLOSE. Po skorygowaniu R²_adj = 0,09872. Tę wartość można uznać za dosyć niską (model w obecnej formie jest słaby), co sugeruje, że istnieje wiele innych czynników wpływających na zmiany rentowności obligacji, których nie uwzględniono.

\newpage

# Testowanie modelu

## Testowanie normalności rozkładu reszt

Testy normalności sprawdzają czy reszty mają rozkład normalny.

H0: Reszty mają rozkład normalny\
H1: Reszty nie mają rozkładu normalny\
Poziom istotności: α = 0,05

```{r, echo=FALSE}

# Przygotowanie reszt
residuals_model <- residuals(model)
fitted_values <- fitted(model)
n_obs <- length(residuals_model)
n_params <- length(coef(model))

```

### Test Shapiro-Wilka

```{r, echo=FALSE,  comment=NA}

  shapiro_test <- shapiro.test(residuals_model)
  cat("   Statystyka W =", round(shapiro_test$statistic, 4), "\n")
  cat("   p-value =", round(shapiro_test$p.value, 4), "\n")
  
```

Statystyka W = 0,9842, p-value = 0,0079

Wniosek: Odrzucamy H0 - reszty nie są normalne

### Test Jarque-Bera

```{r, echo=FALSE, comment=NA,}
# Test Jarque-Bera
jb_test <- jarque.bera.test(residuals_model)
cat("   Statystyka JB =", round(jb_test$statistic, 4), "\n")
cat("   p-value =", round(jb_test$p.value, 4), "\n")

```

Statystyka JB = 12,1445 p-value = 0,0023

Wniosek: Odrzucamy H0 - reszty nie są normalne

### Wykresy normalności

```{r, comment=NA, echo=FALSE}

par(mfrow = c(2, 2))
hist(residuals_model, breaks = 20, prob = TRUE, main = "Histogram reszt", 
     xlab = "Reszty", ylab = "Gęstość")
lines(density(residuals_model), col = "red", lwd = 2)
curve(dnorm(x, mean = mean(residuals_model), sd = sd(residuals_model)), 
      add = TRUE, col = "blue", lwd = 2)
legend("topright", c("Rzeczywista", "Teoretyczna"), col = c("red", "blue"), lwd = 2)

qqnorm(residuals_model,
       main = "Wykres Q-Q reszt",
       xlab = "Kwantyle teoretyczne",
       ylab = "Kwantyle próbkowe")    
qqline(residuals_model, col = "red")

```

Dane zostały już zlogarytmowane. Próba usunięcia braku normalnośći została wykonana. Nie udało się wyeliminować tego problemu

## Testowanie autokorelacji

Autokorelacja oznacza korelację między resztami w różnych okresach

H0: Brak autokorelacji reszt\
H1: Występuje autokorelacja reszt

### Test Durbina-Watsona

```{r,  comment=NA,echo=FALSE}

dw_test <- durbinWatsonTest(model)

cat("   Statystyka DW =", round(dw_test$dw, 4), "\n")
cat("   p-value =", round(dw_test$p, 4), "\n")

```

Statystyka DW = 1,8667, p-value = 0,282

Wniosek: Nie ma podstaw do odrzucenia H0 - brak autokorelacji

### Test Ljunga-Boxa

```{r, comment=NA, echo=FALSE}

ljung_test <- Box.test(residuals_model, lag = min(10, floor(n_obs/5)), type = "Ljung-Box")
cat("2. TEST LJUNGA-BOXA:\n")
cat("   Statystyka LB =", round(ljung_test$statistic, 4), "\n")
cat("   p-value =", round(ljung_test$p.value, 4), "\n")
```

Statystyka LB = 16,9273, p-value = 0,076

Wniosek: Nie ma podstaw do odrzucenia H0 - brak autokorelacji

### Test Breuscha-Godfreya

```{r,  comment=NA,echo=FALSE}

bg_test <- bgtest(model, order = 2)
cat("   Statystyka LM =", round(bg_test$statistic, 4), "\n")
cat("   p-value =", round(bg_test$p.value, 4), "\n")

```

Statystyka LM = 0,8697, p-value = 0,6474

Wniosek: Nie ma podstaw do odrzucenia H0 - brak autokorelacji

### Wykres autokorelacji

```{r,  comment=NA,echo=FALSE}

acf(residuals_model, main = "Funkcja autokorelacji reszt", lag.max = 20)

```

Wnioski: Udało się osiągnąć brak autokorelacji.

## Badanie heteroskedastyczności

Heteroskedastyczność oznacza niestałą wariancję składnika losowego.

H0: Homoskedastyczność (stała wariancja)\
H1: Heteroskedastyczność (niestała wariancja)

### Test Breuscha-Pagana

```{r,  comment=NA,echo=FALSE}

bp_test <- bptest(model)

cat("   Statystyka BP =", round(bp_test$statistic, 4), "\n")
cat("   p-value =", round(bp_test$p.value, 4), "\n")
```

Statystyka BP = 3,0732, p-value = 0,2151

Wniosek: Nie ma podstaw do odrzucenia H0 - homoskedastyczność

### Test Goldfelda-Quandta

```{r, comment=NA, echo=FALSE}
gq_test <- gqtest(model, order.by = fitted(model))
cat("   Statystyka GQ =", round(gq_test$statistic, 4), "\n")
cat("   p-value =", round(gq_test$p.value, 4), "\n")

```

Statystyka GQ = 0,9087, p-value = 0,6996

Wniosek: Nie ma podstaw do odrzucenia H0 - homoskedastyczność

### Wykresy heteroskedastyczności

```{r,  comment=NA,echo=FALSE}
par(mfrow = c(2, 2))
plot(fitted_values, residuals_model, main = "Reszty vs Wartości dopasowane", 
     xlab = "Wartości dopasowane", ylab = "Reszty")
abline(h = 0, col = "red")

plot(fitted_values, abs(residuals_model), main = "|Reszty| vs Wartości dopasowane", 
     xlab = "Wartości dopasowane", ylab = "|Reszty|")
```

Wnioski: Składnik losowy ma w tym modelu stałą wariancję.

## Testowanie współliniowości

### Test VIF

Współliniowość oznacza wysoką korelację między zmiennymi objaśniającymi.

VIF \> 10: poważna współliniowość\
VIF \> 5: umiarkowana współliniowość\
VIF \< 5: brak problemów ze współliniowością

```{r,  comment=NA,echo=FALSE}

  vif_values <- vif(model)
  max_vif <- max(vif_values)
  cat("Maksymalny VIF wynosi:",max_vif)

```

Wnioski: Maksmalny VIF \< 5 więc brak problemów ze współliniowością

## Testowanie stabilności parametrów

### Test Chowa

Test Chowa sprawdza czy parametry modelu są stabilne w czasie.

H0: Parametry są stabilne\
H1: Parametry nie są stabilne (występuje przełom strukturalny)

Punkt przełomu jest w środku próby

```{r, comment=NA, echo=FALSE}
breakpoint <- floor(n_obs / 2)

chow_test <- sctest(formula_modelu, data = data_stationary, type = "Chow", point = breakpoint)
cat("   Statystyka F =", round(chow_test$statistic, 4), "\n")
cat("   p-value =", round(chow_test$p.value, 4), "\n")
```

Statystyka F = 0,9569, p-value = 0,4138

Wnioski: Nie ma podstaw do odrzucenia H0 - parametry są stabilne

### Test CUSUM

```{r, comment=NA, echo=FALSE}
cusum_test <- efp(formula_modelu, data = data_stationary, type = "Rec-CUSUM")
plot(cusum_test, main = "Test CUSUM stabilności parametrów")

```

## Testowanie stabilności postaci analitycznej

### Test RESET Ramseya

Test RESET sprawdza czy postać funkcyjna modelu jest poprawna.

H0: Model ma poprawną postać funkcyjną\
H1: Model ma niepoprawną postać funkcyjną

```{r,  comment=NA,echo=FALSE}
reset_test <- resettest(model, power = 2:3, type = "fitted")
cat("   Statystyka F =", round(reset_test$statistic, 4), "\n")
cat("   p-value =", round(reset_test$p.value, 4), "\n")
```

Statystyka F = 0,4448, p-value = 0,6415

Wnioski: Nie ma podstaw do odrzucenia H0 - poprawna postać modelu

### Test liczby serii

Test sprawdza czy reszty są losowo rozłożone.

H0: Reszty są losowo rozłożone\
H1: Reszty wykazują systematyczne wzorce

```{r ,  comment=NA,echo=FALSE}
signs <- ifelse(residuals_model > 0, 1, 0)
runs_test <- runs.test(as.factor(signs))
cat("   Statystyka =", round(runs_test$statistic, 4), "\n")
cat("   p-value =", round(runs_test$p.value, 4), "\n")
```

Statystyka = -0,3671, p-value = 0,7135

Wnioski: Nie ma podstaw do odrzucenia H0 - reszty są losowe

## Badanie efektu katalizy

### Test F

Efekt katalizy - jedna zmienna wpływa na siłę oddziaływania innej.

```{r ,  comment=NA,echo=FALSE}
  interaction_vars <- paste(best_hellwig_vars, collapse = " * ")
  formula_interaction <- as.formula(paste("D_CLOSE ~", interaction_vars))
  model_interaction <- lm(formula_interaction, data = data_stationary)
  
  anova_result <- anova(model, model_interaction)
  cat("   Statystyka F =", round(anova_result$F[2], 4), "\n")
  cat("   p-value =", round(anova_result$`Pr(>F)`[2], 4), "\n")
 
```

Statystyka F = 2,6483, p-value = 0,105

Wnioski: Brak istotnego efektu katalizy

## Badanie koincydencji

### Porównanie R²

Koincydencja - zmienna objaśniająca ma wpływ jedynie w określonych okresach.

```{r ,  comment=NA,echo=FALSE}
tercile_1 <- floor(n_obs / 3)
tercile_2 <- floor(2 * n_obs / 3)
data_1 <- data_stationary[1:tercile_1, ]
data_2 <- data_stationary[(tercile_1+1):tercile_2, ]
data_3 <- data_stationary[(tercile_2+1):n_obs, ]
model_1 <- lm(formula_modelu, data = data_1)
model_2 <- lm(formula_modelu, data = data_2)
model_3 <- lm(formula_modelu, data = data_3)



cat("Współczynniki determinacji:\n")
cat("  Okres 1 (obs. 1-", tercile_1, "): R² =", round(summary(model_1)$r.squared, 4), "\n")
cat("  Okres 2 (obs.", tercile_1+1, "-", tercile_2, "): R² =", round(summary(model_2)$r.squared, 4), "\n")
cat("  Okres 3 (obs.", tercile_2+1, "-", n_obs, "): R² =", round(summary(model_3)$r.squared, 4), "\n\n")

# Porównanie parametrów
cat("PORÓWNANIE PARAMETRÓW W PODOKRESACH:\n")
coef_1 <- coef(model_1)
coef_2 <- coef(model_2)
coef_3 <- coef(model_3)

for(param in names(coef_1)) {
  cat("Parametr", param, ":\n")
  cat("  Okres 1:", round(coef_1[param], 4), "\n")
  cat("  Okres 2:", round(coef_2[param], 4), "\n")
  cat("  Okres 3:", round(coef_3[param], 4), "\n")
  
  # Sprawdź czy parametry znacząco się różnią
  diff_12 <- abs(coef_1[param] - coef_2[param])
  diff_23 <- abs(coef_2[param] - coef_3[param])
  diff_13 <- abs(coef_1[param] - coef_3[param])
  
  cat("\n")
}
```

\newpage

# Podsumowanie wyników

```{r , comment=NA, echo=FALSE}

test_results <- data.frame(
  Test = c("Normalność (Jarque-Bera)", "Autokorelacja (Ljung-Box)", 
           "Heteroskedastyczność (Breusch-Pagan)", "Współliniowość (max VIF)",
           "Stabilność (Chow)", "Postać modelu (RESET)"),
  Statystyka = c(round(jb_test$statistic, 3), round(ljung_test$statistic, 3),
                round(bp_test$statistic, 3), ifelse(length(best_hellwig_vars) > 1, round(max(vif_values), 3), "N/A"),
                round(chow_test$statistic, 3), round(reset_test$statistic, 3)),
  p_value = c(round(jb_test$p.value, 3), round(ljung_test$p.value, 3),
             round(bp_test$p.value, 3), "N/A", round(chow_test$p.value, 3), round(reset_test$p.value, 3)),
  Wynik = c(ifelse(jb_test$p.value > 0.05, "SPEŁNIONE", "NIESPEŁNIONE"),
           ifelse(ljung_test$p.value > 0.05, "SPEŁNIONE", "NIESPEŁNIONE"),
           ifelse(bp_test$p.value > 0.05, "SPEŁNIONE", "NIESPEŁNIONE"),
           ifelse(length(best_hellwig_vars) > 1, ifelse(max(vif_values) < 5, "SPEŁNIONE", "NIESPEŁNIONE"), "SPEŁNIONE"),
           ifelse(chow_test$p.value > 0.05, "SPEŁNIONE", "NIESPEŁNIONE"),
           ifelse(reset_test$p.value > 0.05, "SPEŁNIONE", "NIESPEŁNIONE"))
)

print(test_results)

# Ogólna ocena modelu
failed_tests <- sum(test_results$Wynik == "NIESPEŁNIONE")
total_tests <- nrow(test_results)

cat("Spełnione założenia:", total_tests - failed_tests, "/", total_tests, "\n")
cat("Niespełnione założenia:", failed_tests, "/", total_tests, "\n\n")


```

# Ocena istotności zmiennych

## Test t-Studenta dla poszczególnych parametrów

Test t-Studenta jest wykorzystywany do oceny **istotności statystycznej** poszczególnych współczynników regresji.\
Dla każdego parametru testuje się hipotezę zerową H0, że dany współczynnik jest równy zero co oznacza, że zmienna objaśniająca nie ma liniowego wpływu na zmienną zależną wobec hipotezy alternatywnej H1, że współczynnik jest różny od zera.

```{r, echo=FALSE, comment=NA}

model_summary <- summary(model)
coefficients_df <- as.data.frame(model_summary$coefficients)
names(coefficients_df) <- c("Estimate", "Std. Error", "t value", "Pr(>|t|)")


param_names <- rownames(coefficients_df)
param_tvalues <- coefficients_df$`t value`
param_pvalues <- coefficients_df$`Pr(>|t|)`
significance_level <- 0.05 # Standardowy poziom istotności alfa

for(i in 1:length(param_names)) {
  param_name <- param_names[i]
  t_val <- param_tvalues[i]
  p_val <- param_pvalues[i]
  is_significant <- p_val < significance_level
  signif_code <- ""
  if (p_val < 0.001) {
    signif_code <- "***"
  } else if (p_val < 0.01) {
    signif_code <- "**"
  } else if (p_val < 0.05) {
    signif_code <- "*"
  } else if (p_val < 0.1) {
    signif_code <- "."
  }
}
```
Parametr: **Wyraz wolny**\
  Wartość t: -1.5419 \
  Wartość p: 0.1244  \
  Wniosek: Współczynnik jest statystycznie nieistotny na poziomie 5%. Brak wystarczających dowodów, aby odrzucić hipotezę zerową, co oznacza, że wyraz wolny prawdopodobnie nie ma istotnego liniowego wpływu na D_CLOSE.\

Parametr: **D_WIG20**\
  Wartość t: -4.503 \
  Wartość p: 1.04e-05 *** \
  Wniosek: Współczynnik jest **statystycznie istotny** na poziomie 5%. Odrzucamy hipotezę zerową, co oznacza, że zmienna D_WIG20 ma istotny wpływ na zmienną D_CLOSE.\

Parametr: **D_OIL**\
  Wartość t: 3.7843 \
  Wartość p: 0.0001942 *** \
  Wniosek: Współczynnik jest **statystycznie istotny** na poziomie 5%. Odrzucamy hipotezę zerową, co oznacza, że zmienna D_OIL ma istotny wpływ na zmienną D_CLOSE.\


## Test Walda (test łącznej istotności)

H0: β1 = β2 = β3 = 0 (wszystkie parametry strukturalne równe zero) H1: co najmniej jeden βi ≠ 0

```{r, echo=FALSE}
model_summary <- summary(model)
f_statistic <- model_summary$fstatistic
f_value <- f_statistic[1]
f_df1 <- f_statistic[2]
f_df2 <- f_statistic[3]
f_p_value <- pf(f_value, f_df1, f_df2, lower.tail = FALSE)

cat("Statystyka F:", round(f_value, 4), "\n")
cat("Stopnie swobody:", f_df1, "i", f_df2, "\n")
cat("p-value:", if(f_p_value < 0.001) "< 0.001" else round(f_p_value, 6), "\n")


```

Statystyka F: 14.4175, df: 2 i 243, p-value: \< 0.001

Wnioski: Odrzucamy H0 - model jako całość jest istotny statystycznie

```{r comment=NA,echo=FALSE}
coeffs <- coef(model)
equation <- "D_CLOSE = "

for(i in 1:length(coeffs)) {
  if(i == 1) {
    equation <- paste0(equation, round(coeffs[i], 6))
  } else {
    sign <- if(coeffs[i] >= 0) " + " else " - "
    equation <- paste0(equation, sign, abs(round(coeffs[i], 6)), " × ", names(coeffs)[i])
  }
}
equation <- paste0(equation, " + ε")

cat(equation, "\n\n")



param_names <- rownames(coefficients_df)
param_values <- coefficients_df$Estimate
param_pvalues <- coefficients_df$`Pr(>|t|)`

```

# Interpretacja parametrów

## Wyraz wolny

Wartość: -0.005865\
Istotność statystyczna: NIEISTOTNY (p = 0.1244)\
Interpretacja: Wyraz wolny - średnia wartość D_CLOSE, gdy wszystkie zmienne objaśniające przyjmują wartość zero.\
Kierunek wpływu: UJEMNY\
Siła oddziaływania: UMIARKOWANA\

## D_WIG20

Wartość: -0.263429 Istotność statystyczna: ISTOTNY (p = 0)\
Interpretacja: Wzrost zmiennej 'D_WIG20' o 1 jednostkę powoduje spadek pierwszej różnicy zmiennej 'CLOSE' o 0.263429 jednostek, ceteris paribus.\
Kierunek wpływu: UJEMNY\
Siła oddziaływania: SILNA\

## D_OIL

Wartość: 0.155374\
Istotność statystyczna: ISTOTNY (p = 2e-04)\
Interpretacja: Wzrost zmiennej 'D_OIL' o 1 jednostkę powoduje wzrost pierwszej różnicy zmiennej 'CLOSE' o 0.155374 jednostek, ceteris paribus.\
Kierunek wpływu: DODATNI\
Siła oddziaływania: SILNA\


# Testowanie modelu na zbiorze testowym


```{r, echo=FALSE, comment=NA}

pred   <- predict(model, newdata = data_test_stationary)
actual <- data_test_stationary$D_CLOSE


MAE   <- mean(abs(actual - pred))
RMSE  <- sqrt(mean((actual - pred)^2))
rel_err <- abs(actual - pred) / abs(actual)
MAPE  <- mean(rel_err) * 100
sMAPE <- mean(2 * abs(actual - pred) / (abs(actual) + abs(pred))) * 100

cat("=== WYNIKI EX POST (zbiór testowy) ===\n")
cat("MAE   =", round(MAE, 6), "\n")
cat("RMSE  =", round(RMSE, 6), "\n")
cat("MAPE  =", round(MAPE, 2),  "%\n")
cat("sMAPE =", round(sMAPE, 2), "%\n")

plot(actual, type = "l", col = "black", lwd = 2,
     main = "Rzeczywiste vs prognoza (zbiór testowy)",
     ylab = "D_CLOSE (różnice log)", xlab = "czas")
lines(pred, col = "red", lwd = 2)
legend("topleft", legend = c("Rzeczywiste", "Prognoza"),
       col = c("black", "red"), lwd = 2, bty = "n")

```
## Interptretacja wyników

Wskaźniki MAE = 0,082 i RMSE = 0,110 świadczą o stosunkowo niskim bezwzględnym błędzie prognoz. Natomiast MAPE = 167,3% oraz sMAPE = 153,12% są zawyżone z uwagi na dzielenie przez bardzo małe wartości zmiennej D_CLOSE (różnice logarytmiczne rentowności). W takich przypadkach bardziej reprezentatywne są miary bezwzględne.

\newpage

# Podsumowanie

## Dane

Dane: Źródłem był serwis Stooq; wstępnie uzupełniono luki interpolacją liniową, następnie podzielono na zbiór treningowy (80 %) i testowy (20 %)

## Selekcja zmiennych i obróbka

Zbiór początkowy liczył 11 zmiennych, po obliczeniu korelacji odrzucono te z |r|>0,8 (np. XAUUSD, WIBOR, USDPLN, 10YDEBOND, 10YUSBOND, DETAL, INFLATION).

Wszystkie wybrane szeregi okazały się niestacjonarne (ADF i KPSS), więc przekształciłem je przez różnicowanie (pierwsze lub drugie rzędu), aż uzyskano stacjonarne serie.

Zmienną D_UNEMPLOYMENT usunięto ze względu na praktycznie zerową wariancję.


## Metoda Hellwiga i konstrukcja modelu

Zastosowano metodę pojemności Hellwiga do wyboru najlepszego podzbioru predyktorów. Najwyższa pojemność (0,0705) wystąpiła dla kombinacji D_WIG20 i D_OIL.

Ostateczny model liniowy: D_CLOSE = -0.005865 - 0.263429 × D_WIG20 + 0.155374 × D_OIL + εD_CLOSE = -0.005865 - 0.263429 × D_WIG20 + 0.155374 × D_OIL + ε.

Wskaźnik R² ≈ 0,106, co oznacza, że zmienne objaśniające wyjaśniają ok. 10,6 % wariancji D_CLOSE; po uwzględnieniu stopnia swobody R²_adj ≈ 0,099 .


## Weryfikacja założeń i testy

### Normalność

Normalność reszt: Shapiro-Wilk (W = 0,984; p = 0,0079) i Jarque-Bera (JB = 12,14; p = 0,0023) wskazują na odrzucenie normalności.

### Autokorelacja

Autokorelacja: Durbin-Watson (DW = 1,867; p = 0,282), Ljung-Box (LB = 16,93; p = 0,076) i Breusch-Godfrey (LM = 0,8697; p = 0,6474) nie wykazały autokorelacji reszt.

### Heteroskedastyczność

Heteroskedastyczność: Breusch-Pagan (BP = 3,073; p = 0,2151) i Goldfeld-Quandt (GQ = 0,9087; p = 0,6996) sugerują homoskedastyczność.

### Współliniowość

Współliniowość: maks. VIF < 5, brak problemów.

### Stabilność parametrów

Stabilność parametrów: test Chow (F = 0,9569; p = 0,4138) i CUSUM nie wskazały na przełom strukturalny.

### Forma funkcjonalna

Forma funkcjonalna: RESET (F = 0,4448; p = 0,6415) – brak dowodów na niepoprawność postaci modelu.

### Losowość reszt

Losowość reszt: test ragów (runs) (statystyka = −0,367; p = 0,7135) – brak systematycznych wzorców. 

## Istotność zmiennych

### Wyraz wolny

Wyraz wolny – nieistotny (p = 0,1244).

### D_WIG20

D_WIG20: t = −4,503; p ≈ 1,04×10⁻⁵ – istotny (wpływ ujemny).

### D_OIL

D_OIL: t = 3,784; p = 0,00019 – istotny (wpływ dodatni).

### Test F 

Test F (Walda) dla modelu ogólnie: F = 14,42; p < 0,001 – model jako całość jest istotny.

## Ocena prognoz na zbiorze testowym

### MAE

MAE ≈ 0,082; RMSE ≈ 0,110 – stosunkowo niewielkie bezwzględne błędy.

### MAPE

MAPE ≈ 167,3 %; sMAPE ≈ 153,1 % – wartości wysokie z uwagi na małe wartości D_CLOSE (logarytmiczne różnice).

Wykres rzeczywistych i prognozowanych D_CLOSE pokazuje dobrą zgodność na ogólnym trendzie, choć przy gwałtownych zmianach model niedoszacowuje lub przeszacowuje momentami. 